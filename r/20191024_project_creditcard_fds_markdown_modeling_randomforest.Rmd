---
output:
  html_document:
    theme: spacelab
  pdf_document: default
---
---
title: "fds_creditcard"
subtitle: "20191024_project_creditcard_fds_markdown_modeling"
author: "정경진"
date: "`r format(Sys.Date())`"
output: 
  html_document: 
    number_sections: yes
    theme: spacelab
    toc: yes
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## step 3. 데이터 modeling

**<credit card fraud protection by 비지도학습>**  


FDS의 주요 분석/탐지 방법은 다음과 같다.  
 
 
**1. 오용탐지 (Misuse)**  

패턴탐지/상태전이 분석모델을 사용한다.
금융거래정보들 중 ‘사기’에 해당하는 정보들을 통계,휴리스틱 등의 방법을 사용하여 시그니처(=룰, 규칙)를 정의하고, 이를 기반으로 ‘사기’와 ‘비(非) 사기’를 판별
전문가 시스템(Expert System)으로 볼 수 있으며, 빠르고 단순한 구조

issue : 잘 알려지지 않은 ‘사기’ 패턴의 경우 기존에 등록된 시그니처로 탐지되지 않아 발견이 어려움


**2. 이상탐지 (Anomaly)**  

지도학습/비지도학습/하이브리드(지도+비지도) 분석모델을 사용한다.  

**2-1. 지도학습**

분석/탐지를 위해 수집되어진 금융거래정보들을 ‘사기’,‘비(非) 사기’로 태깅하고, 두 영역을 학습하여 각 경우에 대한 일반적인 패턴을 추출
추출된 금융거래패턴을 이용하여 새롭게 입력되는 금융거래가 ‘사기’인지 ‘비(非) 사기’인지 판별

issue : 수집된 대용량 금융거래정보들 중 ‘사기’에 해당하는 정보가 많지 않고, 태깅된 정보들로 만드는 것이 어려움. 이러한 이슈로 비지도학습 또는 하이브리드(지도학습+ 비지도학습) 방법이 사용

**2-2. 비지도학습**

수집되어진 금융거래정보들을 태깅하지 않고, 시스템이 정보들을 분석하여 그룹화
각 그룹은 ‘사기’, ‘비(非) 사기’ 등으로 분류되고, 그룹별 특성과 새롭게 입력되는 금융거래의 특성을 비교하여 ‘사기’인지 ‘비(非) 사기’인지 판별

issue : 사기’ 거래정보에 대한 정확한 태킹 없이 학습함으로 지도학습 방법에 비해 오탐률이 높을 수 있음

**2-3. 하이브리드 학습**

금융거래정보들 중 적은양의 일부를 ‘사기’, ‘비(非) 사기’ 태깅하고, 나머지는 태깅이 없는 형태로 학습

**오용탐지와 이상탐지 방법이 가진 단점을 상호 보완하는 하이브리드 탐지 : 알려지지 않은 ‘사기’ 패턴은 이상탐지로 탐지하고, 상대적으로 높은 이상탐지의 오탐률을 오용탐지로 감소하도록 한다**

현재까지 룰 기반의 오용탐지 방법이 많이 사용되고 있지만 최근 딥러닝 기반의 이상탐지 또는 하이브리드(오용+이상) 탐지 방법이 도입 중이다.
(머신러닝 기반의 이상거래 탐지시스템 동향.금융보안원 보안기술연구팀, 2017.8.25. 참고)  


**<본 프로젝트에서의 알고리즘 선정 기준>**  


  FDS의 주요 분석/탐지 방법 중 이상탐지를 주요 목적으로 삼고자 한다. 그 이유는 패턴탐지와 상태전이는 이미 '사기'에 해당하는 정보등을 활용하여 규칙을 만드는 행위이므로, Creditcard Dataset 안의 fraud 데이터로는 규칙을 찾아내는 행위 자체가 불가능할 뿐 아니라, Dataset의 목적이 이상치를 예측하는 것이기 때문이다. **따라서 본 프로젝트에서는 이상탐지(Anomaly) 분석방법을 사용한다.**
  
  Creditcard Data는 v1~v28까지의 임의의 변수가 있고, Class = {0, 1}이 있어 지도학습이 가능하다. 그러나 현업에서의 실제 데이터는 임의의 변수 + Class가 없는 상태(답을 알 수 없는 상태)이므로 machine learning이 패턴을 감지하여 자율적으로 지식을 발견하고, 패턴에 어긋나는 이상패턴을 찾아내는 과정을 거쳐야 한다. 즉, 현업 데이터가 사전에 label되어 있지 않기 때문에 비지도학습을 통한 이상탐지가 필요하다.  

  
  국내외 금융회사의 머신러닝 기반 FDS 활용은 다음과 같다.  
  - (Paypal) 딥러닝 기반의 FDS가 금융거래 고객 약 1억 7천만명이 발생시킨 약 40억 건의 거래정보를 학습하여 사기 탐지를 수행  
  - (Sul America) 보험 클레임의 약 20%가 사기, 남용 등에서 비롯된 것을 파악하고, 보험금 지급 및 클레임 과정에서의 정확성, 유효성 등을 확인하고자 딥러닝 기반 시스템을 도입  
  -(신한은행) 딥러닝 기반 FDS의 모형을 구축하고, 개발한 학습모형 16개에 대해 기존 방식과의 정확도 비교 결과 딥러닝기반 모형의 우수성 확인  
  -(SK증권) 룰 방식(오용탐지)과 딥러닝 방식(이상탐지)이 혼합된 하이브리드(오용+이상 탐지) FDS 도입  
  -(한국스마트카드) 딥러닝 기반 FDS를 구축하였고, 시스템오류를 이상거래로 탐지하는 등의 오탐이 발견되었으나 실제이상거래에 대해서는 우수한 탐지 성능을 보임  
  

  대부분 **딥러닝** 방식을 사용하여 이상탐지를 활용하는 것으로 보인다.   
  
  그 밖에 많이 쓰이는 머신러닝 기법은 다음과 같다.   
  
  규칙 유도(Rule Induction) / 랜덤포레스트(Random Forest) / 의사결정나무(Decision Tree) / 서포트벡터머신(SVM, Support Vector Machine) / 자기조직화맵(SOM, Self-Organizing Map) / 은닉마코브모델(HMM, Hidden Markov Model) / 유전알고리즘(GA, Genetic Algorithm) (머신러닝 기반의 이상거래 탐지시스템 동향.금융보안원 보안기술연구팀, 2017.8.25. 참고)  


 **Kaggle / Googling 으로 조사한 머신러닝 기법(최신 - 2019년 post을 기준으로 한다)**  
 
 
- 의사결정트리에서 출발한 **Isolation forest** 
: googling - blog https://jaehyeongan.github.io/ 참고

- 현업에서 많이 쓰이는 **신경망** 중 **autoencoder**(Keras::)
: https://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/ 참고

- 모든 문제에 대해 잘 수행되는 다목적 모델(지도학습)인 **SVM**
: (US Credit Issuer) 랜덤포레스트, 서포트벡터머신 등 여러 머신러닝 알고리즘을 활용한 시스템을 도입하여 이상거래의 탐지율 향상(머신러닝 기반의 이상거래 탐지시스템 동향.금융보안원 보안기술연구팀, 2017.8.25. 참고)

 ..etc  
 
 
<결론>  

본 프로젝트에서는 

1. 데이터 수준에서의 접근   
1-1. unsampling + random forest
1-2. under sampling + random forest
1-3. smote sampling + random forest

를 수행하고 세가지를 비교하여 가장 정확도가 높은 sampling기법을 찾기로 한다.  
  
2. 알고리즘 수준에서의 접근  
   Deep learning - Autoencoder

를 수행한다.

두 가지의 접근방식을 AUC로 비교하여 하나의 모델 및 resampling 방식을 채택한다.
이후 실제 보험사기 데이터를 가지고 예측해보고자 한다.

**SVM을 사용하는 이유**


  SVM은 머신러닝 지도기법 중 하나로 분류 문제에 적용할 수 있는 알고리즘이다. 이상 탐지 분야에서 가장 큰 영역 중 하나인 네트워크 침입 탐지에서 SVM은 좋은 성능을 보이고, 이미지 분야에서의 이상탐지도 잘 수행하며, 신용카드 사기 탐지(credit card fraud detection)를 위한 비교 실험에서 SVM은 인공신경망과 비슷한 수준의 좋은 성능을 보여준다. 
(김동효, 구해모, 김형주, "DBMS 환경에서 이상 탐지를 위한 SVM과 리샘플링 기법의 분석" p.444, 정보과학회 컴퓨팅의 실제 논문지 제 24 권 제 9 호, 2018. 9)

  또한 re-sampling(1. 데이터 수준에서의 접근)을 통해서 검증 결과를 향상시키는 것이 가능하기 때문에 SVM 알고리즘을 선택하였다.
  
  **SVM 설계**
  
  SVM의 목표는 공간을 나눠 양쪽에 매우 균질적인 분할을 생성하는 초평면을 생성하는 것이다. kNN과 선형회귀 모델링을 결합하여 복잡한 관계도 모델링이 가능하다.  
  
  train/test set에서 non_sampling은 시간 순으로 200000 이후를 test data, 200000 이전을 train data로 나누었다.(이후 정규화함 : x_test/x_train)
  under_sampling은 0과 1의 비율을 1:1로 맞추어 주었다. SMOTE sampling은 교차검증(k=10)의 option(sampling = "smote")을 주었다.
  
  각각의 데이터를 활용하여 SVM을 학습시키고 어떠한 resampling 기법을 사용한 데이터집합이 SVM으로 학습했을 때 가장 좋은 성능을 보이는지 분석한다. 그 후, SVM의 임계값을 조정하여 검증지표가 어떻게 변화하는지 분석해보고 그 결과를 최적화한다.
  
  학습한 SVM 모델의 예측함수는 다음과 같다.
  $$w_1x_1 + w_2x_2 + ... +w_nx_n + intercept > threshold$$
  x는 입력 데이터의 벡터값, w는 SVM을 학습함으로써 얻어진 계수, intercept는 결정경계의 상수 값이다. 좌변의 값이 threshold(임계값)보다 크면 해당 데이터의 클래스를 사기로 예측한다. threshold의 default값은 0으로 두고, 이 값을 조정함으로써 검증지표의 성능을 향상시킨다.   

  커널함수는 SVC(Support Vector Machine Classifier)를 많은 횟수로 생성해야 하기 때문에, 시간은 빠르되 검증결과가 상대적으로 좋은 커널함수를 사용하기로 한다. "DBMS 환경에서 이상 탐지를 위한 SVM과 리샘플링 기법의 분석"에서의 표2. 신용카드 데이터에서 임의 추출한 데이터 개수에 따른 서포트벡터머신의 학습시간을 참고하여 본 결과, 커널함수를 사용하지 않는 linearSVC의 경우가 데이터 갯수에 대해 확장성이 있고, 검증 성능도 상대적으로 좋았다. 따라서 현 프로젝트에서는 linearSVC를 사용하기로 한다.
  
(김동효, 구해모, 김형주, "DBMS 환경에서 이상 탐지를 위한 SVM과 리샘플링 기법의 분석" p.444, 정보과학회 컴퓨팅의 실제 논문지 제 24 권 제 9 호, 2018. 9 참고)  


  **SVM의 R에서의 한계점**
  
  linearSVC를 R에서는 사용할 수 없었으며(python 기반), 기존의 SVM(kernlab 패키지 기반)으로 모델을 학습시키는 시간이 30분 이상으로 길었다. 대용량 데이터 (약 227,846개의 데이터)에서는 학습 수행 시간이 너무 길어져서 사용하기 부적합했다. 커널함수를 다르게 시도하여 보았을 때는 학습시간은 짧지만 검증결과가 좋지 않았다. SMOTE sampling을 caret::train의 교차검증 옵션의 하나로 주기 때문에, linearSVC를 사용할 수 없는 것 또한 문제가 되었다. 따라서 SVM 알고리즘을 지금 데이터에서 R 기반으로 학습하기에는 부적합하다고 판단하였다.
  
   
<수정된 결론>   

1. 데이터 수준에서의 접근   
   unsampling + random forest
   under sampling + random forest
   smote sampling + random forest

2. 알고리즘 수준에서의 접근  
   Deep learning - Autoencoder
   isoltation forest              
   
   을 수행한다.

두 가지의 접근방식을 비교하여 하나의 모델 및 resampling 방식을 채택한다.  


```{r include=FALSE}

#알고리즘을 위한 밑작업 : 
# package 설치 -> 본 프로젝트에서는 SMOTE sampling 기법을 caret package의 train에서 조절하므로 train()함수의 모델 옵션 리스트에 있는지 확인해야 한다. (http://topepo.github.io/caret/train-models-by-tag.html#Linear_Regression caret package page에서 확인할 수 있다. )

#sampling했던 변수들을 불러온다.
load(file = "fds_sampling.RData")

#kernlab install
install.packages("kernlab")
library(kernlab)
```

## SVM with unsampling

```{r}
table(df_train$Class)
#      0      1 
# 199615    385 

# df_train$Class = 0.00192비율로 1 포함
table(df_test$Class)
#     0     1 
# 84700   107 

# df_test$Class = 0.00126비율로 1 포함 (test의 1 비율이 조금 더 적은 것을 알 수 있다.)

# 모델을 위한 밑작업
library(randomForest)
x_train_df <- as.data.frame(x_train)

#data modeling - random forest
set.seed(1031)
rf_unsampling <- randomForest(x_train_df, y_train)

```

### SVM with under - sampling

```{r}

```

## SVM with SMOTE sampling

```{r}

```

##

```{r}

```

## 
```{r}

```

##

